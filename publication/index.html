<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  






























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Publication | Chen Jing (陈婧)</title>

<link rel="icon" href="/images/icon.jpg">

<meta name="title" content="Publication">
<meta name="description" content="An engaging 1-3 sentence description of your lab.">

<meta property="og:title" content="Publication">
<meta property="og:site_title" content="Chen Jing (陈婧)">
<meta property="og:description" content="An engaging 1-3 sentence description of your lab.">
<meta property="og:url" content="https://chenjing-pku.github.io">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Publication">
<meta property="twitter:description" content="An engaging 1-3 sentence description of your lab.">
<meta property="twitter:url" content="https://chenjing-pku.github.io">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Publication",
    "description": "An engaging 1-3 sentence description of your lab.",
    "headline": "Publication",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/images/icon.jpg" }
    },
    "url": "https://chenjing-pku.github.io"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="https://chenjing-pku.github.io/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.7.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.7.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/details.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/table-wrap.js"></script>

  <script src="/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/images/background.jpg')" data-dark="true">
  <a href="/" class="home">
    
      <span class="logo">
        
          <img src="/images/logo.png" alt="logo">
        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">Chen Jing (陈婧)</span>
        
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/publication/" data-tooltip="Published works">
          Publication
        </a>
      
    
      
        <a href="/resources/" data-tooltip="Software, datasets, and more">
          Resources
        </a>
      
    
      
        <a href="/team/" data-tooltip="Team">
          Team
        </a>
      
    
      
        <a href="/projects/" data-tooltip="Software, datasets, and more">
          Projects
        </a>
      
    
      
        <a href="/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="page">
    <h1 id="publication">
<i class="icon fa-solid fa-microscope"></i>Publication</h1>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  <background></background>
  <dark></dark>
  <size></size>
-->

<h2 id="all">All</h2>

<div class="search-box">
  <input type="text" class="search-input" oninput="onSearchInput(this)" placeholder="Search items on this page">
  <button disabled data-tooltip="Clear search" aria-label="clear search" onclick="onSearchClear()">
    <i class="icon fa-solid fa-magnifying-glass"></i>
  </button>
</div>

<div class="search-info"></div>

<h3 id="2025">2025</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9gsvn" class="citation-image" aria-label="Using Ear-EEG to Decode Auditory Attention in Multiple-speaker Environment">
        <img src="" alt="Using Ear-EEG to Decode Auditory Attention in Multiple-speaker Environment" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9gsvn" class="citation-title">
        Using Ear-EEG to Decode Auditory Attention in Multiple-speaker Environment
      </a>

      <div class="citation-authors" tabindex="0">
        Haolin Zhu, Yujie Yan, Xiran Xu, Zhongshu Ge, Pei Tian, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">06 Apr 2025</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP49660.2025.10890810</span>
      </div>

      
        

        
          <div class="citation-buttons">
            
              



  <div class="button-wrapper">
    <a class="button" href="https://zenodo.org/records/10803261" data-tooltip="Data" data-style="bare" aria-label="Data">
      <i class="icon fa-solid fa-database"></i>
      
        <span>Data</span>
      
    </a>
  </div>


            
          </div>
        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9gsvm" class="citation-image" aria-label="A Novel Multimodal Method for Decoding Speech Perception from Brain Activities">
        <img src="" alt="A Novel Multimodal Method for Decoding Speech Perception from Brain Activities" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9gsvm" class="citation-title">
        A Novel Multimodal Method for Decoding Speech Perception from Brain Activities
      </a>

      <div class="citation-authors" tabindex="0">
        Aoke Zhang, Bo Wang, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">06 Apr 2025</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP49660.2025.10889637</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2024">2024</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9qwf3" class="citation-image" aria-label="Auditory Attention Decoding in Four-Talker Environment with EEG">
        <img src="" alt="Auditory Attention Decoding in Four-Talker Environment with EEG" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9qwf3" class="citation-title">
        Auditory Attention Decoding in Four-Talker Environment with EEG
      </a>

      <div class="citation-authors" tabindex="0">
        Yujie Yan, Xiran Xu, Haolin Zhu, Pei Tian, Zhongshu Ge, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Interspeech 2024</span>
         · 
        <span class="citation-date">01 Sep 2024</span>
         · 
        <span class="citation-id">doi:10.21437/Interspeech.2024-739</span>
      </div>

      
        

        
          <div class="citation-buttons">
            
              



  <div class="button-wrapper">
    <a class="button" href="https://zenodo.org/records/10803229" data-tooltip="Data" data-style="bare" aria-label="Data">
      <i class="icon fa-solid fa-database"></i>
      
        <span>Data</span>
      
    </a>
  </div>


            
          </div>
        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f36b" class="citation-image" aria-label="Semantic Reconstruction of Continuous Language from Meg Signals">
        <img src="" alt="Semantic Reconstruction of Continuous Language from Meg Signals" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f36b" class="citation-title">
        Semantic Reconstruction of Continuous Language from Meg Signals
      </a>

      <div class="citation-authors" tabindex="0">
        Bo Wang, Xiran Xu, Longxiang Zhang, Boda Xiao, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">14 Apr 2024</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP48485.2024.10448281</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9h39m" class="citation-image" aria-label="ConvConcatNet: A Deep Convolutional Neural Network to Reconstruct Mel Spectrogram from the EEG">
        <img src="" alt="ConvConcatNet: A Deep Convolutional Neural Network to Reconstruct Mel Spectrogram from the EEG" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9h39m" class="citation-title">
        ConvConcatNet: A Deep Convolutional Neural Network to Reconstruct Mel Spectrogram from the EEG
      </a>

      <div class="citation-authors" tabindex="0">
        Xiran Xu, Bo Wang, Yujie Yan, Haolin Zhu, Zechen Zhang, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)</span>
         · 
        <span class="citation-date">14 Apr 2024</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSPW62465.2024.10626859</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f35h" class="citation-image" aria-label="A DenseNet-Based Method for Decoding Auditory Spatial Attention with EEG">
        <img src="" alt="A DenseNet-Based Method for Decoding Auditory Spatial Attention with EEG" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f35h" class="citation-title">
        A DenseNet-Based Method for Decoding Auditory Spatial Attention with EEG
      </a>

      <div class="citation-authors" tabindex="0">
        Xiran Xu, Bo Wang, Yujie Yan, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">14 Apr 2024</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP48485.2024.10448013</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9h37p" class="citation-image" aria-label="Self-Supervised Speech Representation and Contextual Text Embedding for Match-Mismatch Classification with EEG Recording">
        <img src="" alt="Self-Supervised Speech Representation and Contextual Text Embedding for Match-Mismatch Classification with EEG Recording" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9h37p" class="citation-title">
        Self-Supervised Speech Representation and Contextual Text Embedding for Match-Mismatch Classification with EEG Recording
      </a>

      <div class="citation-authors" tabindex="0">
        Bo Wang, Xiran Xu, Zechen Zhang, Haolin Zhu, YuJie Yan, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)</span>
         · 
        <span class="citation-date">14 Apr 2024</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSPW62465.2024.10625969</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2023">2023</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f36d" class="citation-image" aria-label="EEG-based auditory attention decoding with audiovisual speech for hearing-impaired listeners">
        <img src="" alt="EEG-based auditory attention decoding with audiovisual speech for hearing-impaired listeners" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f36d" class="citation-title">
        EEG-based auditory attention decoding with audiovisual speech for hearing-impaired listeners
      </a>

      <div class="citation-authors" tabindex="0">
        Bo Wang, Xiran Xu, Yadong Niu, Chao Wu, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Cerebral Cortex</span>
         · 
        <span class="citation-date">25 Sep 2023</span>
         · 
        <span class="citation-id">doi:10.1093/cercor/bhad325</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f36f" class="citation-image" aria-label="Emotion Classification with EEG Responses Evoked by Emotional Prosody of Speech">
        <img src="" alt="Emotion Classification with EEG Responses Evoked by Emotional Prosody of Speech" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f36f" class="citation-title">
        Emotion Classification with EEG Responses Evoked by Emotional Prosody of Speech
      </a>

      <div class="citation-authors" tabindex="0">
        Zechen Zhang, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">INTERSPEECH 2023</span>
         · 
        <span class="citation-date">20 Aug 2023</span>
         · 
        <span class="citation-id">doi:10.21437/Interspeech.2023-412</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f36g" class="citation-image" aria-label="PGSS: Pitch-Guided Speech Separation">
        <img src="" alt="PGSS: Pitch-Guided Speech Separation" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f36g" class="citation-title">
        PGSS: Pitch-Guided Speech Separation
      </a>

      <div class="citation-authors" tabindex="0">
        Xiang Li, Yiwen Wang, Yifan Sun, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Proceedings of the AAAI Conference on Artificial Intelligence</span>
         · 
        <span class="citation-date">26 Jun 2023</span>
         · 
        <span class="citation-id">doi:10.1609/aaai.v37i11.26542</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f36c" class="citation-image" aria-label="A Model-Based Hearing Compensation Method Using a Self-Supervised Framework">
        <img src="" alt="A Model-Based Hearing Compensation Method Using a Self-Supervised Framework" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f36c" class="citation-title">
        A Model-Based Hearing Compensation Method Using a Self-Supervised Framework
      </a>

      <div class="citation-authors" tabindex="0">
        Yadong Niu, Nan Li, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">04 Jun 2023</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP49357.2023.10095767</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2022">2022</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g4jdvp" class="citation-image" aria-label="Multi-Speaker Pitch Tracking via Embodied Self-Supervised Learning">
        <img src="" alt="Multi-Speaker Pitch Tracking via Embodied Self-Supervised Learning" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g4jdvp" class="citation-title">
        Multi-Speaker Pitch Tracking via Embodied Self-Supervised Learning
      </a>

      <div class="citation-authors" tabindex="0">
        Xiang Li, Yifan Sun, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">23 May 2022</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP43922.2022.9747262</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2021">2021</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9fvqd" class="citation-image" aria-label="Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing">
        <img src="" alt="Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9fvqd" class="citation-title">
        Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing
      </a>

      <div class="citation-authors" tabindex="0">
        Feng Wang, Jing Chen, Fei Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Interspeech 2021</span>
         · 
        <span class="citation-date">30 Aug 2021</span>
         · 
        <span class="citation-id">doi:10.21437/interspeech.2021-24</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gpz2k5" class="citation-image" aria-label="Eye-gaze Estimation with HEOG and Neck EMG using Deep Neural Networks">
        <img src="" alt="Eye-gaze Estimation with HEOG and Neck EMG using Deep Neural Networks" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gpz2k5" class="citation-title">
        Eye-gaze Estimation with HEOG and Neck EMG using Deep Neural Networks
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Bo Wang, Fei Chen, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2021 29th European Signal Processing Conference (EUSIPCO)</span>
         · 
        <span class="citation-date">23 Aug 2021</span>
         · 
        <span class="citation-id">doi:10.23919/eusipco54536.2021.9616059</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9fvqp" class="citation-image" aria-label="Auditory Attention Decoding from EEG using Convolutional Recurrent Neural Network">
        <img src="" alt="Auditory Attention Decoding from EEG using Convolutional Recurrent Neural Network" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9fvqp" class="citation-title">
        Auditory Attention Decoding from EEG using Convolutional Recurrent Neural Network
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Bo Wang, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2021 29th European Signal Processing Conference (EUSIPCO)</span>
         · 
        <span class="citation-date">23 Aug 2021</span>
         · 
        <span class="citation-id">doi:10.23919/eusipco54536.2021.9616195</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9fvqq" class="citation-image" aria-label="Categorical perception of lexical tones based on acoustic-electric stimulation">
        <img src="" alt="Categorical perception of lexical tones based on acoustic-electric stimulation" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9fvqq" class="citation-title">
        Categorical perception of lexical tones based on acoustic-electric stimulation
      </a>

      <div class="citation-authors" tabindex="0">
        Yadong Niu, Yuhe Liu, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">JASA Express Letters</span>
         · 
        <span class="citation-date">01 Aug 2021</span>
         · 
        <span class="citation-id">doi:10.1121/10.0005807</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gpc7wk" class="citation-image" aria-label="Common Brain Substrates Underlying Auditory Speech Priming and Perceived Spatial Separation">
        <img src="" alt="Common Brain Substrates Underlying Auditory Speech Priming and Perceived Spatial Separation" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gpc7wk" class="citation-title">
        Common Brain Substrates Underlying Auditory Speech Priming and Perceived Spatial Separation
      </a>

      <div class="citation-authors" tabindex="0">
        Junxian Wang, Jing Chen, Xiaodong Yang, Lei Liu, Chao Wu, Lingxi Lu, Liang Li, Yanhong Wu

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Frontiers in Neuroscience</span>
         · 
        <span class="citation-date">17 Jun 2021</span>
         · 
        <span class="citation-id">doi:10.3389/fnins.2021.664985</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2020">2020</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gmkgzq" class="citation-image" aria-label="Congruent Audiovisual Speech Enhances Cortical Envelope Tracking During Auditory Selective Attention">
        <img src="" alt="Congruent Audiovisual Speech Enhances Cortical Envelope Tracking During Auditory Selective Attention" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gmkgzq" class="citation-title">
        Congruent Audiovisual Speech Enhances Cortical Envelope Tracking During Auditory Selective Attention
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Interspeech 2020</span>
         · 
        <span class="citation-date">25 Oct 2020</span>
         · 
        <span class="citation-id">doi:10.21437/interspeech.2020-1957</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38f" class="citation-image" aria-label="Single-Channel Speech Separation Integrating Pitch Information Based on a Multi Task Learning Framework">
        <img src="" alt="Single-Channel Speech Separation Integrating Pitch Information Based on a Multi Task Learning Framework" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38f" class="citation-title">
        Single-Channel Speech Separation Integrating Pitch Information Based on a Multi Task Learning Framework
      </a>

      <div class="citation-authors" tabindex="0">
        Xiang Li, Rui Liu, Tao Song, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">01 May 2020</span>
         · 
        <span class="citation-id">doi:10.1109/icassp40776.2020.9053460</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2019">2019</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/ghddhq" class="citation-image" aria-label="Congruent audiovisual speech enhances auditory attention decoding with EEG">
        <img src="" alt="Congruent audiovisual speech enhances auditory attention decoding with EEG" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/ghddhq" class="citation-title">
        Congruent audiovisual speech enhances auditory attention decoding with EEG
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Journal of Neural Engineering</span>
         · 
        <span class="citation-date">06 Nov 2019</span>
         · 
        <span class="citation-id">doi:10.1088/1741-2552/ab4340</span>
      </div>

      
        

        
          <div class="citation-buttons">
            
              



  <div class="button-wrapper">
    <a class="button" href="https://disk.pku.edu.cn/link/AAA0E62E014EF44B40BBCAB46B2FED7227" data-tooltip="Data" data-style="bare" aria-label="Data">
      <i class="icon fa-solid fa-database"></i>
      
        <span>Data</span>
      
    </a>
  </div>


            
          </div>
        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38j" class="citation-image" aria-label="Brainstem encoding of frequency-modulated sweeps is relevant to Mandarin concurrent-vowels identification for normal-hearing and hearing-impaired listeners">
        <img src="" alt="Brainstem encoding of frequency-modulated sweeps is relevant to Mandarin concurrent-vowels identification for normal-hearing and hearing-impaired listeners" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38j" class="citation-title">
        Brainstem encoding of frequency-modulated sweeps is relevant to Mandarin concurrent-vowels identification for normal-hearing and hearing-impaired listeners
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Hongying Yang, Fei Chen, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Hearing Research</span>
         · 
        <span class="citation-date">01 Sep 2019</span>
         · 
        <span class="citation-id">doi:10.1016/j.heares.2019.06.005</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38k" class="citation-image" aria-label="The effect of F0 contour on the intelligibility of Mandarin Chinese for hearing-impaired listeners">
        <img src="" alt="The effect of F0 contour on the intelligibility of Mandarin Chinese for hearing-impaired listeners" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38k" class="citation-title">
        The effect of F0 contour on the intelligibility of Mandarin Chinese for hearing-impaired listeners
      </a>

      <div class="citation-authors" tabindex="0">
        Yadong Niu, Fei Chen, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Aug 2019</span>
         · 
        <span class="citation-id">doi:10.1121/1.5119264</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38m" class="citation-image" aria-label="The effect of speech material on the band importance function for Mandarin Chinese">
        <img src="" alt="The effect of speech material on the band importance function for Mandarin Chinese" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38m" class="citation-title">
        The effect of speech material on the band importance function for Mandarin Chinese
      </a>

      <div class="citation-authors" tabindex="0">
        Yufan Du, Yi Shen, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Jul 2019</span>
         · 
        <span class="citation-id">doi:10.1121/1.5116691</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38h" class="citation-image" aria-label="A Spectral-change-aware Loss Function for DNN-based Speech Separation">
        <img src="" alt="A Spectral-change-aware Loss Function for DNN-based Speech Separation" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38h" class="citation-title">
        A Spectral-change-aware Loss Function for DNN-based Speech Separation
      </a>

      <div class="citation-authors" tabindex="0">
        Xiang Li, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">01 May 2019</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP.2019.8683850</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38g" class="citation-image" aria-label="Integrating Spectrotemporal Context into Features Based on Auditory Perception for Classification-based Speech Separation">
        <img src="" alt="Integrating Spectrotemporal Context into Features Based on Auditory Perception for Classification-based Speech Separation" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38g" class="citation-title">
        Integrating Spectrotemporal Context into Features Based on Auditory Perception for Classification-based Speech Separation
      </a>

      <div class="citation-authors" tabindex="0">
        Xiang Li, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">01 May 2019</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP.2019.8682503</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/ghkvmf" class="citation-image" aria-label="Perceptual contributions of vowels and consonant-vowel transitions in simulated electric-acoustic hearing">
        <img src="" alt="Perceptual contributions of vowels and consonant-vowel transitions in simulated electric-acoustic hearing" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/ghkvmf" class="citation-title">
        Perceptual contributions of vowels and consonant-vowel transitions in simulated electric-acoustic hearing
      </a>

      <div class="citation-authors" tabindex="0">
        Fei Chen, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Mar 2019</span>
         · 
        <span class="citation-id">doi:10.1121/1.5093451</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9h39n" class="citation-image" aria-label="Spectral-change Enhancement with prior SNR for the Hearing Impaired">
        <img src="" alt="Spectral-change Enhancement with prior SNR for the Hearing Impaired" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9h39n" class="citation-title">
        Spectral-change Enhancement with prior SNR for the Hearing Impaired
      </a>

      <div class="citation-authors" tabindex="0">
        Xiang Li, Xin Tian, Henry Luo, Jinyu Qian, Xihong Wu, Dingsheng Luo, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Proceedings of the ICA 2019 and EAA Euroregio : 23rd International Congress on Acoustics</span>
         · 
        <span class="citation-date">01 Jan 2019</span>
         · 
        <span class="citation-id">doi:10.18154/RWTH-CONV-238821</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2018">2018</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38q" class="citation-image" aria-label="Attempt to Predict Temporal Modulation Transfer Function by Amplitude Modulation Following Responses">
        <img src="" alt="Attempt to Predict Temporal Modulation Transfer Function by Amplitude Modulation Following Responses" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38q" class="citation-title">
        Attempt to Predict Temporal Modulation Transfer Function by Amplitude Modulation Following Responses
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Zhen Fu, Jiping Wu, Xihong Wu

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Acta Acustica united with Acustica</span>
         · 
        <span class="citation-date">01 Sep 2018</span>
         · 
        <span class="citation-id">doi:10.3813/AAA.919237</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gfjss7" class="citation-image" aria-label="Acoustic Cues Utilized by Normal-hearing and Hearing-impaired Listeners Are Different for Mandarin Concurrent-vowels Identification">
        <img src="" alt="Acoustic Cues Utilized by Normal-hearing and Hearing-impaired Listeners Are Different for Mandarin Concurrent-vowels Identification" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gfjss7" class="citation-title">
        Acoustic Cues Utilized by Normal-hearing and Hearing-impaired Listeners Are Different for Mandarin Concurrent-vowels Identification
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Hongying Yang, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Acta Acustica united with Acustica</span>
         · 
        <span class="citation-date">01 Sep 2018</span>
         · 
        <span class="citation-id">doi:10.3813/AAA.919225</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gdn62p" class="citation-image" aria-label="Effects of fundamental frequency contour on understanding Mandarin sentences in bimodal hearing simulations">
        <img src="" alt="Effects of fundamental frequency contour on understanding Mandarin sentences in bimodal hearing simulations" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gdn62p" class="citation-title">
        Effects of fundamental frequency contour on understanding Mandarin sentences in bimodal hearing simulations
      </a>

      <div class="citation-authors" tabindex="0">
        Fei Chen, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 May 2018</span>
         · 
        <span class="citation-id">doi:10.1121/1.5037720</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38p" class="citation-image" aria-label="A Time-Weighted Method for Predicting the Intelligibility of Speech in the Presence of Interfering Sounds">
        <img src="" alt="A Time-Weighted Method for Predicting the Intelligibility of Speech in the Presence of Interfering Sounds" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38p" class="citation-title">
        A Time-Weighted Method for Predicting the Intelligibility of Speech in the Presence of Interfering Sounds
      </a>

      <div class="citation-authors" tabindex="0">
        Mingjie Song, Fei Chen, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>
         · 
        <span class="citation-date">01 Apr 2018</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP.2018.8462124</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gdkghv" class="citation-image" aria-label="Emotionally conditioning the target-speech voice enhances recognition of the target speech under cocktail-party listening conditions">
        <img src="" alt="Emotionally conditioning the target-speech voice enhances recognition of the target speech under cocktail-party listening conditions" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gdkghv" class="citation-title">
        Emotionally conditioning the target-speech voice enhances recognition of the target speech under “cocktail-party” listening conditions
      </a>

      <div class="citation-authors" tabindex="0">
        Lingxi Lu, Xiaohan Bao, Jing Chen, Tianshu Qu, Xihong Wu, Liang Li

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Attention, Perception, &amp; Psychophysics</span>
         · 
        <span class="citation-date">22 Feb 2018</span>
         · 
        <span class="citation-id">doi:10.3758/s13414-018-1489-8</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gc473k" class="citation-image" aria-label="Individually tailored spectral-change enhancement for the hearing impaired">
        <img src="" alt="Individually tailored spectral-change enhancement for the hearing impaired" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gc473k" class="citation-title">
        Individually tailored spectral-change enhancement for the hearing impaired
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Brian C. J. Moore, Thomas Baer, Xihong Wu

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Feb 2018</span>
         · 
        <span class="citation-id">doi:10.1121/1.5024894</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gc3282" class="citation-image" aria-label="The effect of F0 contour on the intelligibility of speech in the presence of interfering sounds for Mandarin Chinese">
        <img src="" alt="The effect of F0 contour on the intelligibility of speech in the presence of interfering sounds for Mandarin Chinese" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gc3282" class="citation-title">
        The effect of F0 contour on the intelligibility of speech in the presence of interfering sounds for Mandarin Chinese
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Hongying Yang, Xihong Wu, Brian C. J. Moore

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Feb 2018</span>
         · 
        <span class="citation-id">doi:10.1121/1.5023218</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38n" class="citation-image" aria-label="An Environment-Adaptation Based Binaural Localization Method">
        <img src="" alt="An Environment-Adaptation Based Binaural Localization Method" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38n" class="citation-title">
        An Environment-Adaptation Based Binaural Localization Method
      </a>

      <div class="citation-authors" tabindex="0">
        Tao Song, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Lecture Notes in Computer Science</span>
         · 
        <span class="citation-date">01 Jan 2018</span>
         · 
        <span class="citation-id">doi:10.1007/978-3-030-02698-1_4</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2017">2017</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38t" class="citation-image" aria-label="Electrically-evoked frequency following responses EFFRs and electrically-evoked auditory brainstem responses EABRs in guinea pigs">
        <img src="" alt="Electrically-evoked frequency following responses EFFRs and electrically-evoked auditory brainstem responses EABRs in guinea pigs" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38t" class="citation-title">
        Electrically-evoked frequency following responses (EFFRs) and electrically-evoked auditory brainstem responses (EABRs) in guinea pigs
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Zhen Fu, Xiuyong Ding, Jiping Wu, Xihong Wu

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</span>
         · 
        <span class="citation-date">01 Dec 2017</span>
         · 
        <span class="citation-id">doi:10.1109/APSIPA.2017.8282142</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38v" class="citation-image" aria-label="Using frequency-following responses FFRs to evaluate the auditory function of frequency-modulation FM discrimination">
        <img src="" alt="Using frequency-following responses FFRs to evaluate the auditory function of frequency-modulation FM discrimination" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38v" class="citation-title">
        Using frequency-following responses (FFRs) to evaluate the auditory function of frequency-modulation (FM) discrimination
      </a>

      <div class="citation-authors" tabindex="0">
        Zhen Fu, Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Applied Informatics</span>
         · 
        <span class="citation-date">23 Oct 2017</span>
         · 
        <span class="citation-id">doi:10.1186/s40535-017-0040-7</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gcp3j3" class="citation-image" aria-label="Towards human-like and transhuman perception in AI 2.0: a review">
        <img src="" alt="Towards human-like and transhuman perception in AI 2.0: a review" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gcp3j3" class="citation-title">
        Towards human-like and transhuman perception in AI 2.0: a review
      </a>

      <div class="citation-authors" data-tooltip="Yong-hong Tian, Xi-lin Chen, Hong-kai Xiong, Hong-liang Li, Li-rong Dai, Jing Chen, Jun-liang Xing, Jing Chen, Xi-hong Wu, Wei-min Hu, Yu Hu, Tie-jun Huang, Wen Gao" tabindex="0">
        Yong-hong Tian, Xi-lin Chen, Hong-kai Xiong, Hong-liang Li, Li-rong Dai, …, Xi-hong Wu, Wei-min Hu, Yu Hu, Tie-jun Huang, Wen Gao

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Frontiers of Information Technology &amp; Electronic Engineering</span>
         · 
        <span class="citation-date">01 Jan 2017</span>
         · 
        <span class="citation-id">doi:10.1631/FITEE.1601804</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2016">2016</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/f8494r" class="citation-image" aria-label="Frequency importance function of the speech intelligibility index for Mandarin Chinese">
        <img src="" alt="Frequency importance function of the speech intelligibility index for Mandarin Chinese" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/f8494r" class="citation-title">
        Frequency importance function of the speech intelligibility index for Mandarin Chinese
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Qiang Huang, Xihong Wu

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Speech Communication</span>
         · 
        <span class="citation-date">01 Oct 2016</span>
         · 
        <span class="citation-id">doi:10.1016/j.specom.2016.07.009</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2014">2014</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gmbqm8" class="citation-image" aria-label="Electrically-Evoked Frequency-Following Response EFFR in the Auditory Brainstem of Guinea Pigs">
        <img src="" alt="Electrically-Evoked Frequency-Following Response EFFR in the Auditory Brainstem of Guinea Pigs" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gmbqm8" class="citation-title">
        Electrically-Evoked Frequency-Following Response (EFFR) in the Auditory Brainstem of Guinea Pigs
      </a>

      <div class="citation-authors" tabindex="0">
        Wenxin He, Xiuyong Ding, Ruxiang Zhang, Jing Chen, Daoxing Zhang, Xihong Wu

      </div>

      <div class="citation-details">
        <span class="citation-publisher">PLoS ONE</span>
         · 
        <span class="citation-date">22 Sep 2014</span>
         · 
        <span class="citation-id">doi:10.1371/journal.pone.0106719</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38c" class="citation-image" aria-label="Binaural Sound Source Localization in Noisy Reverberant Environments Based on Equalization-Cancellation Theory">
        <img src="" alt="Binaural Sound Source Localization in Noisy Reverberant Environments Based on Equalization-Cancellation Theory" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38c" class="citation-title">
        Binaural Sound Source Localization in Noisy Reverberant Environments Based on Equalization-Cancellation Theory
      </a>

      <div class="citation-authors" tabindex="0">
        Thanh-Duc CHAU, Junfeng LI, Masato AKAGI

      </div>

      <div class="citation-details">
        <span class="citation-publisher">IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences</span>
         · 
        <span class="citation-date">01 Jan 2014</span>
         · 
        <span class="citation-id">doi:10.1587/transfun.e97.a.2011</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2013">2013</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f39x" class="citation-image" aria-label="Effect of individually tailored spectral change enhancement on speech intelligibility and quality for hearing-impaired listeners">
        <img src="" alt="Effect of individually tailored spectral change enhancement on speech intelligibility and quality for hearing-impaired listeners" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f39x" class="citation-title">
        Effect of individually tailored spectral change enhancement on speech intelligibility and quality for hearing-impaired listeners
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Brian C.J. Moore

      </div>

      <div class="citation-details">
        <span class="citation-publisher">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</span>
         · 
        <span class="citation-date">01 May 2013</span>
         · 
        <span class="citation-id">doi:10.1109/ICASSP.2013.6639353</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2012">2012</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g7s4k9" class="citation-image" aria-label="Informational masking of speech produced by speech-like sounds without linguistic content">
        <img src="" alt="Informational masking of speech produced by speech-like sounds without linguistic content" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g7s4k9" class="citation-title">
        Informational masking of speech produced by speech-like sounds without linguistic content
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Huahui Li, Liang Li, Xihong Wu, Brian C. J. Moore

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Apr 2012</span>
         · 
        <span class="citation-id">doi:10.1121/1.3688510</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/gfsbzq" class="citation-image" aria-label="Effect of enhancement of spectral changes on speech intelligibility and clarity preferences for the hearing impaired">
        <img src="" alt="Effect of enhancement of spectral changes on speech intelligibility and clarity preferences for the hearing impaired" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/gfsbzq" class="citation-title">
        Effect of enhancement of spectral changes on speech intelligibility and clarity preferences for the hearing impaired
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Thomas Baer, Brian C. J. Moore

      </div>

      <div class="citation-details">
        <span class="citation-publisher">The Journal of the Acoustical Society of America</span>
         · 
        <span class="citation-date">01 Apr 2012</span>
         · 
        <span class="citation-id">doi:10.1121/1.3689556</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f39z" class="citation-image" aria-label="A computational model for assessment of speech intelligibility in informational masking">
        <img src="" alt="A computational model for assessment of speech intelligibility in informational masking" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f39z" class="citation-title">
        A computational model for assessment of speech intelligibility in informational masking
      </a>

      <div class="citation-authors" tabindex="0">
        Xihong Wu, Jing Chen

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Frontiers of Electrical and Electronic Engineering</span>
         · 
        <span class="citation-date">22 Feb 2012</span>
         · 
        <span class="citation-id">doi:10.1007/s11460-012-0189-8</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2011">2011</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/c76b6v" class="citation-image" aria-label="Cross-Language Differences in Informational Masking of Speech by Speech: English Versus Mandarin Chinese">
        <img src="" alt="Cross-Language Differences in Informational Masking of Speech by Speech: English Versus Mandarin Chinese" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/c76b6v" class="citation-title">
        Cross-Language Differences in Informational Masking of Speech by Speech: English Versus Mandarin Chinese
      </a>

      <div class="citation-authors" tabindex="0">
        Xihong Wu, Zhigang Yang, Ying Huang, Jing Chen, Liang Li, Meredyth Daneman, Bruce A. Schneider

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Journal of Speech, Language, and Hearing Research</span>
         · 
        <span class="citation-date">01 Dec 2011</span>
         · 
        <span class="citation-id">doi:10.1044/1092-4388(2011/10-0282)</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2010">2010</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f392" class="citation-image" aria-label="Effects of enhancement of spectral changes on speech quality and subjective speech intelligibility">
        <img src="" alt="Effects of enhancement of spectral changes on speech quality and subjective speech intelligibility" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f392" class="citation-title">
        Effects of enhancement of spectral changes on speech quality and subjective speech intelligibility
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Thomas Baer, Brian C. J. Moore

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Interspeech 2010</span>
         · 
        <span class="citation-date">26 Sep 2010</span>
         · 
        <span class="citation-id">doi:10.21437/interspeech.2010-474</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2009">2009</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/dcdbzs" class="citation-image" aria-label="Simulated Phase-Locking Stimulation: An Improved Speech Processing Strategy for Cochlear Implants">
        <img src="" alt="Simulated Phase-Locking Stimulation: An Improved Speech Processing Strategy for Cochlear Implants" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/dcdbzs" class="citation-title">
        Simulated Phase-Locking Stimulation: An Improved Speech Processing Strategy for Cochlear Implants
      </a>

      <div class="citation-authors" tabindex="0">
        Jing Chen, Xihong Wu, Liang Li, Huisheng Chi

      </div>

      <div class="citation-details">
        <span class="citation-publisher">ORL</span>
         · 
        <span class="citation-date">01 Jan 2009</span>
         · 
        <span class="citation-id">doi:10.1159/000229302</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2007">2007</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/bfk3qm" class="citation-image" aria-label="The effect of voice cuing on releasing Chinese speech from informational masking">
        <img src="" alt="The effect of voice cuing on releasing Chinese speech from informational masking" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/bfk3qm" class="citation-title">
        The effect of voice cuing on releasing Chinese speech from informational masking
      </a>

      <div class="citation-authors" tabindex="0">
        Zhigang Yang, Jing Chen, Qiang Huang, Xihong Wu, Yanhong Wu, Bruce A. Schneider, Liang Li

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Speech Communication</span>
         · 
        <span class="citation-date">01 Dec 2007</span>
         · 
        <span class="citation-id">doi:10.1016/j.specom.2007.05.005</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f393" class="citation-image" aria-label="Effect of number of masking talkers on speech-on-speech masking in Chinese">
        <img src="" alt="Effect of number of masking talkers on speech-on-speech masking in Chinese" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f393" class="citation-title">
        Effect of number of masking talkers on speech-on-speech masking in Chinese
      </a>

      <div class="citation-authors" tabindex="0">
        Xihong Wu, Jing Chen, Zhigang Yang, Qiang Huang, Mengyuan Wang, Liang Li

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Interspeech 2007</span>
         · 
        <span class="citation-date">27 Aug 2007</span>
         · 
        <span class="citation-id">doi:10.21437/interspeech.2007-195</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3 id="2005">2005</h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/bwj795" class="citation-image" aria-label="The effect of perceived spatial separation on informational masking of Chinese speech">
        <img src="" alt="The effect of perceived spatial separation on informational masking of Chinese speech" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/bwj795" class="citation-title">
        The effect of perceived spatial separation on informational masking of Chinese speech
      </a>

      <div class="citation-authors" tabindex="0">
        Xihong Wu, Chun Wang, Jing Chen, Hongwei Qu, Wenrui Li, Yanhong Wu, Bruce A. Schneider, Liang Li

      </div>

      <div class="citation-details">
        <span class="citation-publisher">Hearing Research</span>
         · 
        <span class="citation-date">01 Jan 2005</span>
         · 
        <span class="citation-id">doi:10.1016/j.heares.2004.03.010</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<h3></h3>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38s" class="citation-image" aria-label="人机校验-万方医学网">
        <img src="" alt="人机校验-万方医学网" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38s" class="citation-title">
        人机校验-万方医学网
      </a>

      <div class="citation-authors" tabindex="0">
        

      </div>

      <div class="citation-details">
        <span class="citation-publisher">[no publisher info]</span>
         · 
        <span class="citation-date">[no date info]</span>
         · 
        <span class="citation-id">doi:10.3969/j.issn.1672-4933.2018.02.005</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>

<div class="citation-container">
  <div class="citation">
    
      <a href="https://doi.org/g9f38d" class="citation-image" aria-label="不同言语识别能力的老年性聋耳蜗电图特征分析-论文-万方医学网">
        <img src="" alt="不同言语识别能力的老年性聋耳蜗电图特征分析-论文-万方医学网" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="citation-text">
      
      <i class="icon fa-solid fa-scroll"></i>

      <a href="https://doi.org/g9f38d" class="citation-title">
        不同言语识别能力的老年性聋耳蜗电图特征分析-论文-万方医学网
      </a>

      <div class="citation-authors" tabindex="0">
        

      </div>

      <div class="citation-details">
        <span class="citation-publisher">[no publisher info]</span>
         · 
        <span class="citation-date">[no date info]</span>
         · 
        <span class="citation-id">doi:10.3969/j.issn.1672-2922.2021.03.009</span>
      </div>

      
        

        

        
      
    </div>
  </div>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="mailto:janechenjing@pku.edu.cn" data-tooltip="Email" data-style="bare" aria-label="Email">
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2025
    Chen Jing (陈婧)
      |   Built with
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
